# di25-learnings
<p class="intro">
This is a collection and recollection of all the 14 members of the 2025 class of <a href="https://cjddatainstitute.org/">The Data Institute</a> — a collaboration between the <a href="https://cfjd.howard.edu/">Center for Journalism & Democracy</a> and the <a href="https://idabwellssociety.org/">Ida B. Wells Society for Investigative Reporting</a> — learned July 7 to July 18 in Atlanta, Georgia. A member of our cohort, <a href="https://www.ncat.edu/employee-bio.php?directoryID=690815680">Nicole Watson</a>, had the idea to collate the tools we discussed during our two weeks. Below is an attempt at doing so. The repo for the class can be found <a href="https://github.com/cjddatainstitute/data-institute-2025/blob/main/README.md">here</a>.
</p>

<h2>Now, here are some tools.</h2>

<dl class="get_data">
<h3>How to get data:</h3>
  <dt>Google Advanced Search</dt>
    <dd>Though simple, <a href="https://www.google.com/advanced_search">Google Advanced Search</a> is your friend. Try searching a domain for only a pdf or an csv file and see what you get.</dd>
<dt>Request generator</dt>
  <dd>The Student Press Law Center has a <a href="https://splc.org/lettergenerator/"> public records letter generator</a> that will write a bulletproof request. Muckrock has the <a href="https://www.foiamachine.org/">FOIA Machine</a> that will write your request and track it.</dd>
</dl class="get_data">

<dl class="clean_data">
<h3>How to retrieve, load clean data:</h3>
  <dt>Open Refine</dt>
    <dd>Data standardization is way easier with <a href="https://propublica.s3.amazonaws.com/data-institute/open-refine-2025.pdf">Open Refine<a>. Humans know "Delta" and "Delta Airlines" and "Delta Air lines" are the same. Computers don't. This tool uses different linguistics models to analyze the data and makes guesses to help you reconcile.</dd>
  <dt>Tabula</dt>
    <dd>If you have ever cursed at the inability to copy structured data from a PDF, then <a href+"https://tabula.technology/">Tabula</a> is an arrow to have in your quiver.</dd>
  <dt>AI (ohhhhh)</dt>
    <dd>Derek says using <a href="https://docs.google.com/presentation/d/1k_Mui_M5SeDKGyhbAdFw-awfDHHYoOoRHiLrv_FGtRg/edit">artifical intelligence</a> to extract data from documents is the wave of the future.  </dd>
  <dt>HTML and CSS</dt>
    <dd>The programming languages that decide how the internet is structured and looks, <a href="https://projects.propublica.org/graphics/images/data-institute/presentations/2017/html.pdf>HTML</a> and <a href="https://projects.propublica.org/graphics/images/data-institute/presentations/2017/css.pdf>CSS</a>, are useful to know because they help us find structure the extract.</dd>
  <dt>Inspector</dt>
      <dd>In Google Chrome, simply right-click on a webpage and click "<a href="https://developer.chrome.com/docs/devtools/open">Inspect</a>," then before you will open a magical world of information that tells you everything from the exact color of what you're seeing to the struture of the data, which tells you how to scrape the page.</dd>
  <dt>Instant Data Scraper</dt>
      <dd>There's a Chrome extension named <a href="https://chromewebstore.google.com/detail/instant-data-scraper/ofaokhiedipichpaobibbnahnkdoiiah?hl=en-US">Instant Data Scraper</a> that requires no coding knowledge to scrape websites, even ones with infinite scrolls.</dd>
  <dt>Parsehub</dt>
      <dd>A more powerful no-code way to scrape a website is <a href="https://parsehub.com/">Parsehub</a>, which can handle things like subheads and infinite scrolls.</dd>
  <dt>Monitors, scrapers</dt>
      <dd>There are a lot of tools out there to monitor websites and scrape. Among them are <a href="https://distill.io/">Distill</a> and The Marshall Project's <a href="https://www.newsklaxon.org/">Klaxon</a> tool.</dd>
</dl class="clean_data">

<dl class="viz_data">
<h3>How to visualize data:</h3>
    <dt>Datawrapper</dt>
      <dd>The best solution is <a href="https://www.datawrapper.de/">Datawrapper</a> if you want to make fancy, embeddable charts for free.</dd>
    <dt>Tableau</dt>
      <dd>No-code mapping option, <a href="https://www.tableau.com/trial/visualize-your-data">Tableau</a> is free for those with a university email address.</dd>
    <dt>Python</dt>
      <dd>Using modules such as <a href="https://github.com/cjddatainstitute/data-institute-2025/blob/main/real-estate-gentrification-analysis-main/wiki/common_pandas_operations.md">Pandas</a> and <a href="https://matplotlib.org/">matplotlib</a>, Python can be an even easier data visualization powerhouse.</dd>
</dl class="viz_data">

<h4>Our invaluable instructors, structured as they'd surely want to be, include:</h4>
<ul class="instructor_list">
  <li><a href="https://thescoop.org/now/">Derek Willis</a></li>
  <li><a href="https://github.com/ellissimani">Ellis Simani</a></li>
  <li><a href="http://maggielee.net/">Maggie Lee</a></li>
  <li><a href="https://research.auctr.edu/prf.php?id=5a89da03-7cdb-11ed-9922-0ad758b798c3">Brian Briones</a></li>
  <li><a href="https://sisiwei.com/">Sisi Wei</a></li>
  <li><a href="https://www.linkedin.com/in/richard-hackett/">Richard Hackett</a></li>
  <li><a href="https://mikegrant.me/">Michael Grant</a></li>
</ul class="instructor_list">
  
<p><i>We are deeply indebted to them and those who came before us.</i></p>

<p>Below are the learning materials we used. Want to use the slides? The teaching materials fall under the <a href="https://creativecommons.org/licenses/by-nc-nd/3.0/us/">Creative Commons license</a>.</p>

<dl class="weeks">
<dt>Week 1:</dt>
  <dd><a href="https://github.com/cjddatainstitute/data-institute-2025/#day-1">Day 1: Intro to Data Journalism, Spreadsheets, Best Practices</a></dd>
  <dd><a href="https://github.com/cjddatainstitute/data-institute-2025/#day-2">Day 2: Evaluating Data, Open Refine, Analyzing One Variable</a></dd>
  <dd><a href="https://github.com/cjddatainstitute/data-institute-2025/#day-3">Day 3: Tabula, AI, and Putting It All Together</a></dd>
  <dd><a href="https://github.com/cjddatainstitute/data-institute-2025/#day-4">Day 4: Visualizing Data, Charts and Maps</a></dd>
  <dd><a href="https://github.com/cjddatainstitute/data-institute-2025/#day-5">Day 5: Intro to Code, How Websites Work, HTML, CSS</a></dd>
<dt>Week 2:</dt>
  <dd><a href="https://github.com/cjddatainstitute/data-institute-2025/#day-6">Day 6: Intro to Design, Make Your Own Website</a></dd>
  <dd><a href="https://github.com/cjddatainstitute/data-institute-2025/#day-7">Day 7: Web Scraping, Fundamentals of Programming</a></dd>
  <dd><a href="https://github.com/cjddatainstitute/data-institute-2025/#day-8">Day 8: Even More Web Scraping</a></dd>
</dl class="weeks">

<h3>Things to remember, from our instructors:</h3>
  <ol>
    <li>Make a copy! Don't work off the original!</li>
    <li>Keep a <a href="https://cronkitedata.github.io/cronkite-docs/general/04-data-diary.html">data diary</a> so others, and you, know what happened.</li> 
    <li>Computers are dumb! You need to tell them <i>exactly</i> what you want them to do or they get confused.</li>
    <li>Make a unique ID when you create a dataset. Then you can always get it back to the original order.</li>
    <li>If there's a web portal, that means there's a database. So put in a request for that database.</li>
  </ol>

<h4>Quote to remember when approaching data:</h4>
<p class="kicker">“Who’s the worst person I know who could have done this? And how would they have messed this up?” - <i>Derek</i></p>

<p><i>A sincere thank you to the amazing Ida B. Wells Society team helmed by Executive Director Robbie R. Morganfield. They who handled the logistics and snacks and flights that made this possible: Program Manager Arlette Hawkins, Project Manager Kawana Bowman, Finance and Grants Manager Julien C.E. Forrest.</i></p>

<!--This code was written by Ben Brasch doing his best while recovering from a Mary Mac's four-piece chicken lunch, so sorry if anything is wrong.-->
